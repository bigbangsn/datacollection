import streamlit as st
import pandas as pd
from urllib.parse import urlparse
from scrapping import scrape_data, save_to_csv

st.title("ğŸ—ï¸ Scraper les donnÃ©es avec SELENIUM")
st.write("Cette page vous permet de collecter des donnÃ©es depuis diffÃ©rentes sources.")

# URLs disponibles
URLS_DISPONIBLES = {
    "TV & Home Cinema": "https://www.expat-dakar.com/tv-home-cinema",
    "TÃ©lÃ©phones": "https://www.expat-dakar.com/telephones",
    "Ordinateurs": "https://www.expat-dakar.com/ordinateurs"
}

# Initialiser les Ã©tats de session
if "stop" not in st.session_state:
    st.session_state.stop = False
if "scraping_complete" not in st.session_state:
    st.session_state.scraping_complete = False
if "scraped_data" not in st.session_state:
    st.session_state.scraped_data = {}
if "show_data" not in st.session_state:
    st.session_state.show_data = False

st.subheader("Scraping des sources sÃ©lectionnÃ©es")

choix_urls = st.multiselect("Choisissez les catÃ©gories :", list(URLS_DISPONIBLES.keys()))
nb_pages = st.number_input("Nombre de pages Ã  scraper :", min_value=1, max_value=50, value=2)

lancer = st.button("ğŸš€ Lancer le scraping")
stopper = st.button("ğŸ›‘ Stopper le scraping")

if stopper:
    st.session_state.stop = True
    st.warning("â¹ï¸ Le scraping sera interrompu aprÃ¨s la page en cours.")

if lancer and choix_urls:
    st.session_state.stop = False  # RÃ©initialiser le flag

    statut = st.empty()

    total_ops = len(choix_urls)

    # RÃ©initialiser les donnÃ©es scrapÃ©es
    st.session_state.scraped_data = {}

    for nom in choix_urls:
        if st.session_state.stop:
            st.error("â›” Scraping interrompu par l'utilisateur.")
            break

        url = URLS_DISPONIBLES[nom]
        statut.info(f"ğŸ”„ Scraping : {nom}")

        with st.spinner(f"Scraping {nom} en cours..."):
            try:
                data = scrape_data(url, nb_pages)
                filename = f"{"donnee/"+urlparse(url).path.strip('/').split('/')[-1]}.csv"
                save_to_csv(filename, data)

                # Stocker les donnÃ©es dans la session
                st.session_state.scraped_data[nom] = {
                    "data": data,
                    "filename": filename
                }
            except Exception as e:
                st.error(f"âŒ Erreur pour {nom} : {e}")

    # Marquer le scraping comme terminÃ©
    st.session_state.scraping_complete = True
    statut.success("âœ… Scraping terminÃ©." if not st.session_state.stop else "âš ï¸ Scraping partiel terminÃ©.")

elif lancer and not choix_urls:
    st.warning("Veuillez sÃ©lectionner au moins une catÃ©gorie Ã  scraper.")

# Afficher le dialogue aprÃ¨s la fin du scraping
if st.session_state.scraping_complete and st.session_state.scraped_data:
    with st.container():
        st.markdown("---")
        st.subheader("ğŸ‰ Scraping terminÃ© avec succÃ¨s!")
        st.write("Souhaitez-vous afficher les donnÃ©es collectÃ©es?")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ‘ï¸ Afficher les donnÃ©es"):
                st.session_state.show_data = True
        with col2:
            if st.button("âŒ Non merci"):
                st.session_state.show_data = False
                st.session_state.scraping_complete = False

    # Afficher les donnÃ©es si l'utilisateur le souhaite
    if "show_data" in st.session_state and st.session_state.show_data:
        st.markdown("---")
        st.subheader("ğŸ“Š DonnÃ©es collectÃ©es")

        for nom, info in st.session_state.scraped_data.items():
            with st.expander(f"ğŸ“„ RÃ©sultats de {nom}"):
                st.write(f"Fichier sauvegardÃ©: {info['filename']}")
                st.write(pd.DataFrame(info['data'], columns=["DÃ©tails", "Ã‰tat", "Marque", "Adresse", "Prix", "Image"]))

                # Option pour tÃ©lÃ©charger les donnÃ©es
                csv = pd.DataFrame(info['data'], 
                                  columns=["DÃ©tails", "Ã‰tat", "Marque", "Adresse", "Prix", "Image"]).to_csv(index=False)
                st.download_button(
                    label=f"â¬‡ï¸ TÃ©lÃ©charger les donnÃ©es de {nom}",
                    data=csv,
                    file_name=f"{nom.lower().replace(' & ', '-').replace(' ', '-')}.csv",
                    mime="text/csv"
                )
